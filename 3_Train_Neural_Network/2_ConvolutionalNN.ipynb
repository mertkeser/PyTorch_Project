{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DATASET \n",
    "We will first load the dataset. MNIST Dataset is consisted from 70,000 handwritten numeric digital images in the size of 28x28. 60,000 of them are for training and 10,000 of them for test set. MNIST dataset is already in torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Getting the required libraries for loading dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.datasets as dataset\n",
    "\n",
    "mnist_trainset = dataset.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = dataset.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "#Lets Play with this data\n",
    "len(mnist_trainset) #Length of training dataset\n",
    "len(mnist_testset) #Length of test dataset\n",
    "\n",
    "#Learn type of the data\n",
    "print(type(mnist_trainset)) #Shows that type of the data\n",
    "train_image_zero, train_target_zero = mnist_trainset[0] \n",
    "#train_image_zero.show() #Showing the image zero\n",
    "print(train_target_zero.item()) #Class of the iMAGE 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some of Images\n",
    "- We learned how to download our dataset and showed the first index. In the next step, let's visualize them by using matplotlibrary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5 #You should set here how many of them you want to visualize\n",
    "for i in range(5):\n",
    "    im = int(torch.randint(0,len(mnist_trainset),(1,1)).item())\n",
    "    sample_im, label_im = mnist_trainset[im]\n",
    "    ax = plt.subplot(1,n,i+1)\n",
    "    ax.set_title('Class {}'.format(label_im.item()))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(sample_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN\n",
    "- Let's create a Convolutional NN to classify MNIST dataset. Due to the simplicity of exercise, in the first one I will not use autograd or neural network package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop_out): Dropout(p=0.5)\n",
      "  (fc1): Linear(in_features=6272, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mertkeser/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [10/30], Loss: 1.2623\n",
      "Epoch [1/20], Step [20/30], Loss: 0.5420\n",
      "Epoch [1/20], Step [30/30], Loss: 0.6030\n",
      "Train Set Accuracy in Epoch 1/20 is %84.80\n",
      "Test Set Accuracy in Epoch 1/20 is %85.97\n",
      "Epoch [2/20], Step [10/30], Loss: 0.3246\n",
      "Epoch [2/20], Step [20/30], Loss: 0.2995\n",
      "Epoch [2/20], Step [30/30], Loss: 0.2727\n",
      "Train Set Accuracy in Epoch 2/20 is %92.21\n",
      "Test Set Accuracy in Epoch 2/20 is %92.84\n",
      "Epoch [3/20], Step [10/30], Loss: 0.2526\n",
      "Epoch [3/20], Step [20/30], Loss: 0.2517\n",
      "Epoch [3/20], Step [30/30], Loss: 0.2316\n",
      "Train Set Accuracy in Epoch 3/20 is %93.64\n",
      "Test Set Accuracy in Epoch 3/20 is %93.90\n",
      "Epoch [4/20], Step [10/30], Loss: 0.1994\n",
      "Epoch [4/20], Step [20/30], Loss: 0.1974\n",
      "Epoch [4/20], Step [30/30], Loss: 0.1895\n",
      "Train Set Accuracy in Epoch 4/20 is %94.45\n",
      "Test Set Accuracy in Epoch 4/20 is %94.99\n",
      "Epoch [5/20], Step [10/30], Loss: 0.1979\n",
      "Epoch [5/20], Step [20/30], Loss: 0.1654\n",
      "Epoch [5/20], Step [30/30], Loss: 0.1443\n",
      "Train Set Accuracy in Epoch 5/20 is %95.10\n",
      "Test Set Accuracy in Epoch 5/20 is %95.44\n",
      "Epoch [6/20], Step [10/30], Loss: 0.1698\n",
      "Epoch [6/20], Step [20/30], Loss: 0.1856\n",
      "Epoch [6/20], Step [30/30], Loss: 0.1612\n",
      "Train Set Accuracy in Epoch 6/20 is %95.59\n",
      "Test Set Accuracy in Epoch 6/20 is %95.75\n",
      "Epoch [7/20], Step [10/30], Loss: 0.1497\n",
      "Epoch [7/20], Step [20/30], Loss: 0.1487\n",
      "Epoch [7/20], Step [30/30], Loss: 0.1486\n",
      "Train Set Accuracy in Epoch 7/20 is %95.93\n",
      "Test Set Accuracy in Epoch 7/20 is %96.06\n",
      "Epoch [8/20], Step [10/30], Loss: 0.1541\n",
      "Epoch [8/20], Step [20/30], Loss: 0.1152\n",
      "Epoch [8/20], Step [30/30], Loss: 0.1476\n",
      "Train Set Accuracy in Epoch 8/20 is %96.30\n",
      "Test Set Accuracy in Epoch 8/20 is %96.23\n",
      "Epoch [9/20], Step [10/30], Loss: 0.1394\n",
      "Epoch [9/20], Step [20/30], Loss: 0.1043\n",
      "Epoch [9/20], Step [30/30], Loss: 0.1230\n",
      "Train Set Accuracy in Epoch 9/20 is %96.41\n",
      "Test Set Accuracy in Epoch 9/20 is %96.47\n",
      "Epoch [10/20], Step [10/30], Loss: 0.1225\n",
      "Epoch [10/20], Step [20/30], Loss: 0.1315\n",
      "Epoch [10/20], Step [30/30], Loss: 0.0980\n",
      "Train Set Accuracy in Epoch 10/20 is %96.65\n",
      "Test Set Accuracy in Epoch 10/20 is %96.72\n",
      "Epoch [11/20], Step [10/30], Loss: 0.1328\n",
      "Epoch [11/20], Step [20/30], Loss: 0.1224\n",
      "Epoch [11/20], Step [30/30], Loss: 0.1078\n",
      "Train Set Accuracy in Epoch 11/20 is %96.76\n",
      "Test Set Accuracy in Epoch 11/20 is %96.86\n",
      "Epoch [12/20], Step [10/30], Loss: 0.1036\n",
      "Epoch [12/20], Step [20/30], Loss: 0.1188\n",
      "Epoch [12/20], Step [30/30], Loss: 0.1038\n",
      "Train Set Accuracy in Epoch 12/20 is %96.91\n",
      "Test Set Accuracy in Epoch 12/20 is %96.93\n",
      "Epoch [13/20], Step [10/30], Loss: 0.1056\n",
      "Epoch [13/20], Step [20/30], Loss: 0.0880\n",
      "Epoch [13/20], Step [30/30], Loss: 0.1018\n",
      "Train Set Accuracy in Epoch 13/20 is %97.08\n",
      "Test Set Accuracy in Epoch 13/20 is %97.09\n",
      "Epoch [14/20], Step [10/30], Loss: 0.0918\n",
      "Epoch [14/20], Step [20/30], Loss: 0.0827\n",
      "Epoch [14/20], Step [30/30], Loss: 0.0886\n",
      "Train Set Accuracy in Epoch 14/20 is %97.14\n",
      "Test Set Accuracy in Epoch 14/20 is %97.33\n",
      "Epoch [15/20], Step [10/30], Loss: 0.0840\n",
      "Epoch [15/20], Step [20/30], Loss: 0.0936\n",
      "Epoch [15/20], Step [30/30], Loss: 0.0981\n",
      "Train Set Accuracy in Epoch 15/20 is %97.24\n",
      "Test Set Accuracy in Epoch 15/20 is %97.24\n",
      "Epoch [16/20], Step [10/30], Loss: 0.0912\n",
      "Epoch [16/20], Step [20/30], Loss: 0.0999\n",
      "Epoch [16/20], Step [30/30], Loss: 0.0836\n",
      "Train Set Accuracy in Epoch 16/20 is %97.37\n",
      "Test Set Accuracy in Epoch 16/20 is %97.43\n",
      "Epoch [17/20], Step [10/30], Loss: 0.0855\n",
      "Epoch [17/20], Step [20/30], Loss: 0.0903\n",
      "Epoch [17/20], Step [30/30], Loss: 0.0877\n",
      "Train Set Accuracy in Epoch 17/20 is %97.33\n",
      "Test Set Accuracy in Epoch 17/20 is %97.39\n",
      "Epoch [18/20], Step [10/30], Loss: 0.0807\n",
      "Epoch [18/20], Step [20/30], Loss: 0.0873\n"
     ]
    }
   ],
   "source": [
    "# Define Parameters\n",
    "epochs = 20 #Time of the epoch\n",
    "batch_size = 2000 \n",
    "learning_rate = 0.1\n",
    "\n",
    "# Let's load the Data again as Tensor\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=trans,\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=trans)\n",
    "\n",
    "# transforms to apply to the data\n",
    "\n",
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=len(test_dataset))\n",
    "\n",
    "train_loader_whole = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                                 batch_size=len(train_dataset), \n",
    "                                                 shuffle=True)\n",
    "\n",
    "# We already know that each image is in the same size\n",
    "print(len(mnist_trainset))\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(14 * 14 * 32, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return F.log_softmax(out)\n",
    "    \n",
    "#Lets see the instance of this class\n",
    "net = CNN()\n",
    "print(net)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start the learning\n",
    "# Forward-Pass\n",
    "# run the main training loop\n",
    "for epoch in range(epochs):\n",
    "    TrueTrain = 0; TrueTest = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #data = data.reshape(-1, 28*28)\n",
    "        # Forward pass\n",
    "        outputs = net(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{:.0f}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, epochs, batch_idx+1, len(train_dataset)/batch_size, loss.item()))\n",
    "            \n",
    "    for _, (data, target) in enumerate(train_loader_whole): \n",
    "        outputs = net(data)\n",
    "        max_index = outputs.max(dim = 1)[1]\n",
    "        TrueTrain += (max_index == target).sum()\n",
    "\n",
    "    for _, (data, target) in enumerate(test_loader): \n",
    "        outputs = net(data)\n",
    "        max_index = outputs.max(dim = 1)[1]\n",
    "        TrueTest += (max_index == target).sum()\n",
    "    \n",
    "    print( \"Train Set Accuracy in Epoch {}/{} is %{:.2f}\".format( epoch+1, epochs, TrueTrain.item()/len(mnist_trainset) * 100 ) )\n",
    "    print( \"Test Set Accuracy in Epoch {}/{} is %{:.2f}\".format( epoch+1, epochs, TrueTest.item()/len(mnist_testset) * 100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
