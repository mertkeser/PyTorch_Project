{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DATASET \n",
    "We will first load the dataset. MNIST Dataset is consisted from 70,000 handwritten numeric digital images in the size of 28x28. 60,000 of them are for training and 10,000 of them for test set. MNIST dataset is already in torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Getting the required libraries for loading dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.datasets as dataset\n",
    "\n",
    "mnist_trainset = dataset.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = dataset.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "#Lets Play with this data\n",
    "len(mnist_trainset) #Length of training dataset\n",
    "len(mnist_testset) #Length of test dataset\n",
    "\n",
    "#Learn type of the data\n",
    "print(type(mnist_trainset)) #Shows that type of the data\n",
    "train_image_zero, train_target_zero = mnist_trainset[0] \n",
    "#train_image_zero.show() #Showing the image zero\n",
    "print(train_target_zero.item()) #Class of the iMAGE 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some of Images\n",
    "- We learned how to download our dataset and showed the first index. In the next step, let's visualize them by using matplotlibrary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5 #You should set here how many of them you want to visualize\n",
    "for i in range(5):\n",
    "    im = int(torch.randint(0,len(mnist_trainset),(1,1)).item())\n",
    "    sample_im, label_im = mnist_trainset[im]\n",
    "    ax = plt.subplot(1,n,i+1)\n",
    "    ax.set_title('Class {}'.format(label_im.item()))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(sample_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequential NN\n",
    "- Let's create a simple sequantial NN to classify MNIST dataset. Due to the simplicity of exercise, in the first one I will not use autograd or neural network package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "SNN(\n",
      "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/20], Step [10/30], Loss: 1.5329\n",
      "Epoch [1/20], Step [20/30], Loss: 0.5693\n",
      "Epoch [1/20], Step [30/30], Loss: 0.4233\n",
      "Train Set Accuracy in Epoch 1/20 is %87.72\n",
      "Test Set Accuracy in Epoch 1/20 is %88.49\n",
      "Epoch [2/20], Step [10/30], Loss: 0.3831\n",
      "Epoch [2/20], Step [20/30], Loss: 0.3611\n",
      "Epoch [2/20], Step [30/30], Loss: 0.3195\n",
      "Train Set Accuracy in Epoch 2/20 is %90.81\n",
      "Test Set Accuracy in Epoch 2/20 is %91.32\n",
      "Epoch [3/20], Step [10/30], Loss: 0.3118\n",
      "Epoch [3/20], Step [20/30], Loss: 0.2779\n",
      "Epoch [3/20], Step [30/30], Loss: 0.2761\n",
      "Train Set Accuracy in Epoch 3/20 is %92.08\n",
      "Test Set Accuracy in Epoch 3/20 is %92.50\n",
      "Epoch [4/20], Step [10/30], Loss: 0.2709\n",
      "Epoch [4/20], Step [20/30], Loss: 0.2759\n",
      "Epoch [4/20], Step [30/30], Loss: 0.2722\n",
      "Train Set Accuracy in Epoch 4/20 is %92.81\n",
      "Test Set Accuracy in Epoch 4/20 is %92.88\n",
      "Epoch [5/20], Step [10/30], Loss: 0.2670\n",
      "Epoch [5/20], Step [20/30], Loss: 0.2250\n",
      "Epoch [5/20], Step [30/30], Loss: 0.2254\n",
      "Train Set Accuracy in Epoch 5/20 is %93.75\n",
      "Test Set Accuracy in Epoch 5/20 is %93.57\n",
      "Epoch [6/20], Step [10/30], Loss: 0.2381\n",
      "Epoch [6/20], Step [20/30], Loss: 0.1959\n",
      "Epoch [6/20], Step [30/30], Loss: 0.2195\n",
      "Train Set Accuracy in Epoch 6/20 is %94.17\n",
      "Test Set Accuracy in Epoch 6/20 is %94.05\n",
      "Epoch [7/20], Step [10/30], Loss: 0.2131\n",
      "Epoch [7/20], Step [20/30], Loss: 0.2035\n",
      "Epoch [7/20], Step [30/30], Loss: 0.2183\n",
      "Train Set Accuracy in Epoch 7/20 is %94.59\n",
      "Test Set Accuracy in Epoch 7/20 is %94.35\n",
      "Epoch [8/20], Step [10/30], Loss: 0.1869\n",
      "Epoch [8/20], Step [20/30], Loss: 0.1649\n",
      "Epoch [8/20], Step [30/30], Loss: 0.1663\n",
      "Train Set Accuracy in Epoch 8/20 is %95.11\n",
      "Test Set Accuracy in Epoch 8/20 is %94.93\n",
      "Epoch [9/20], Step [10/30], Loss: 0.1966\n",
      "Epoch [9/20], Step [20/30], Loss: 0.1746\n",
      "Epoch [9/20], Step [30/30], Loss: 0.1758\n",
      "Train Set Accuracy in Epoch 9/20 is %95.52\n",
      "Test Set Accuracy in Epoch 9/20 is %95.06\n",
      "Epoch [10/20], Step [10/30], Loss: 0.1690\n",
      "Epoch [10/20], Step [20/30], Loss: 0.1611\n",
      "Epoch [10/20], Step [30/30], Loss: 0.1610\n",
      "Train Set Accuracy in Epoch 10/20 is %95.85\n",
      "Test Set Accuracy in Epoch 10/20 is %95.55\n",
      "Epoch [11/20], Step [10/30], Loss: 0.1523\n",
      "Epoch [11/20], Step [20/30], Loss: 0.1364\n",
      "Epoch [11/20], Step [30/30], Loss: 0.1664\n",
      "Train Set Accuracy in Epoch 11/20 is %96.03\n",
      "Test Set Accuracy in Epoch 11/20 is %95.73\n",
      "Epoch [12/20], Step [10/30], Loss: 0.1420\n",
      "Epoch [12/20], Step [20/30], Loss: 0.1375\n",
      "Epoch [12/20], Step [30/30], Loss: 0.1433\n",
      "Train Set Accuracy in Epoch 12/20 is %96.36\n",
      "Test Set Accuracy in Epoch 12/20 is %95.90\n",
      "Epoch [13/20], Step [10/30], Loss: 0.1217\n",
      "Epoch [13/20], Step [20/30], Loss: 0.1405\n",
      "Epoch [13/20], Step [30/30], Loss: 0.1276\n",
      "Train Set Accuracy in Epoch 13/20 is %96.64\n",
      "Test Set Accuracy in Epoch 13/20 is %96.13\n",
      "Epoch [14/20], Step [10/30], Loss: 0.1118\n",
      "Epoch [14/20], Step [20/30], Loss: 0.1177\n",
      "Epoch [14/20], Step [30/30], Loss: 0.1167\n",
      "Train Set Accuracy in Epoch 14/20 is %96.81\n",
      "Test Set Accuracy in Epoch 14/20 is %96.31\n",
      "Epoch [15/20], Step [10/30], Loss: 0.1193\n",
      "Epoch [15/20], Step [20/30], Loss: 0.0945\n",
      "Epoch [15/20], Step [30/30], Loss: 0.1297\n",
      "Train Set Accuracy in Epoch 15/20 is %96.97\n",
      "Test Set Accuracy in Epoch 15/20 is %96.47\n",
      "Epoch [16/20], Step [10/30], Loss: 0.1092\n",
      "Epoch [16/20], Step [20/30], Loss: 0.1015\n",
      "Epoch [16/20], Step [30/30], Loss: 0.0991\n",
      "Train Set Accuracy in Epoch 16/20 is %97.16\n",
      "Test Set Accuracy in Epoch 16/20 is %96.44\n",
      "Epoch [17/20], Step [10/30], Loss: 0.0927\n",
      "Epoch [17/20], Step [20/30], Loss: 0.0991\n",
      "Epoch [17/20], Step [30/30], Loss: 0.1114\n",
      "Train Set Accuracy in Epoch 17/20 is %97.36\n",
      "Test Set Accuracy in Epoch 17/20 is %96.72\n",
      "Epoch [18/20], Step [10/30], Loss: 0.0862\n",
      "Epoch [18/20], Step [20/30], Loss: 0.0917\n",
      "Epoch [18/20], Step [30/30], Loss: 0.0958\n",
      "Train Set Accuracy in Epoch 18/20 is %97.48\n",
      "Test Set Accuracy in Epoch 18/20 is %96.91\n",
      "Epoch [19/20], Step [10/30], Loss: 0.0925\n",
      "Epoch [19/20], Step [20/30], Loss: 0.1073\n",
      "Epoch [19/20], Step [30/30], Loss: 0.0796\n",
      "Train Set Accuracy in Epoch 19/20 is %97.52\n",
      "Test Set Accuracy in Epoch 19/20 is %96.83\n",
      "Epoch [20/20], Step [10/30], Loss: 0.0891\n",
      "Epoch [20/20], Step [20/30], Loss: 0.0736\n",
      "Epoch [20/20], Step [30/30], Loss: 0.0918\n",
      "Train Set Accuracy in Epoch 20/20 is %97.73\n",
      "Test Set Accuracy in Epoch 20/20 is %97.10\n"
     ]
    }
   ],
   "source": [
    "# Define Parameters\n",
    "epochs = 20 #Time of the epoch\n",
    "batch_size = 2000 \n",
    "learning_rate = 0.1\n",
    "\n",
    "# Let's load the Data again as Tensor\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=len(test_dataset))\n",
    "\n",
    "train_loader_whole = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                                 batch_size=len(train_dataset), \n",
    "                                                 shuffle=True)\n",
    "\n",
    "# We already know that each image is in the same size\n",
    "print(len(mnist_trainset))\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN, self).__init__() #Creates an instance based on nn.Module Class\n",
    "        self.fc1 = nn.Linear(28*28, 200) #First layer of Neural Network\n",
    "        self.fc2 = nn.Linear(200, 10)#Second Layer of Neural Network\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "#Lets see the instance of this class\n",
    "net = SNN()\n",
    "print(net)\n",
    "\n",
    "#Stochastic Optimizer Network\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Start the learning\n",
    "# Forward-Pass\n",
    "# run the main training loop\n",
    "for epoch in range(epochs):\n",
    "    TrueTrain = 0; TrueTest = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.reshape(-1, 28*28)\n",
    "        # Forward pass\n",
    "        outputs = net(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{:.0f}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, epochs, batch_idx+1, len(train_dataset)/batch_size, loss.item()))\n",
    "            \n",
    "    for _, (data, target) in enumerate(train_loader_whole): \n",
    "        data = data.reshape(-1, 28*28)\n",
    "        outputs = net(data)\n",
    "        max_index = outputs.max(dim = 1)[1]\n",
    "        TrueTrain += (max_index == target).sum()\n",
    "\n",
    "    for _, (data, target) in enumerate(test_loader): \n",
    "        data = data.reshape(-1, 28*28)\n",
    "        outputs = net(data)\n",
    "        max_index = outputs.max(dim = 1)[1]\n",
    "        TrueTest += (max_index == target).sum()\n",
    "    \n",
    "    print( \"Train Set Accuracy in Epoch {}/{} is %{:.2f}\".format( epoch+1, epochs, TrueTrain.item()/len(mnist_trainset) * 100 ) )\n",
    "    print( \"Test Set Accuracy in Epoch {}/{} is %{:.2f}\".format( epoch+1, epochs, TrueTest.item()/len(mnist_testset) * 100 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
